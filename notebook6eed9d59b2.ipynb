{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "Neste notebook usaremos várias técnicas e métodos para um problema de classificação de texto, que compreende a análise de sentimentos em uma base de dados financeiros.\n",
    "\n",
    "\n",
    "### O que é análise de sentimento?\n",
    "A Análise de Sentimento é uma tarefa de PLN usada para interpretar as emoções, comentários e avaliações (positivas, negativas ou neutras) por trás dos dados do texto.\n",
    "\n",
    "### Aplicações de análise de sentimento:\n",
    "* Análise de mídia social;\n",
    "* Sentimento público sobre produtos;\n",
    "* Moderação de conteúdo;\n",
    "* Análise do mercado de ações;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:36:56.327321Z",
     "iopub.status.busy": "2024-06-17T23:36:56.326897Z",
     "iopub.status.idle": "2024-06-17T23:36:56.337738Z",
     "shell.execute_reply": "2024-06-17T23:36:56.33643Z",
     "shell.execute_reply.started": "2024-06-17T23:36:56.32729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# nltk imports\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # bags of words e TF-IDF\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:36:57.977353Z",
     "iopub.status.busy": "2024-06-17T23:36:57.976908Z",
     "iopub.status.idle": "2024-06-17T23:36:58.040916Z",
     "shell.execute_reply": "2024-06-17T23:36:58.039702Z",
     "shell.execute_reply.started": "2024-06-17T23:36:57.977318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A tecnologia GeoSolutions aproveitará as soluç...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ Esi em baixos, queda de US $ 1,50 a US $ 2,5...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No último trimestre de 2010, as vendas líquida...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>De acordo com a Câmara de Comércio Finlandesa-...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A empresa de compra sueca vendeu sua participa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  A tecnologia GeoSolutions aproveitará as soluç...  positive\n",
       "1  $ Esi em baixos, queda de US $ 1,50 a US $ 2,5...  negative\n",
       "2  No último trimestre de 2010, as vendas líquida...  positive\n",
       "3  De acordo com a Câmara de Comércio Finlandesa-...   neutral\n",
       "4  A empresa de compra sueca vendeu sua participa...   neutral"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Carregamento do banco\n",
    "# df = pd.read_csv('/kaggle/input/sentiment-analysis/sentiment_analysis.csv')\n",
    "df = pd.read_csv('data/sentiment_analysis_pt_br.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:00.57319Z",
     "iopub.status.busy": "2024-06-17T23:37:00.572752Z",
     "iopub.status.idle": "2024-06-17T23:37:00.582093Z",
     "shell.execute_reply": "2024-06-17T23:37:00.580613Z",
     "shell.execute_reply.started": "2024-06-17T23:37:00.573155Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:02.221508Z",
     "iopub.status.busy": "2024-06-17T23:37:02.221118Z",
     "iopub.status.idle": "2024-06-17T23:37:02.238853Z",
     "shell.execute_reply": "2024-06-17T23:37:02.237447Z",
     "shell.execute_reply.started": "2024-06-17T23:37:02.221479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:04.102123Z",
     "iopub.status.busy": "2024-06-17T23:37:04.101671Z",
     "iopub.status.idle": "2024-06-17T23:37:04.110868Z",
     "shell.execute_reply": "2024-06-17T23:37:04.109613Z",
     "shell.execute_reply.started": "2024-06-17T23:37:04.102088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos visulizar as classes do problema\n",
    "unique_sentiments = df.Sentiment.unique()\n",
    "unique_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:06.170446Z",
     "iopub.status.busy": "2024-06-17T23:37:06.17006Z",
     "iopub.status.idle": "2024-06-17T23:37:06.450455Z",
     "shell.execute_reply": "2024-06-17T23:37:06.448998Z",
     "shell.execute_reply.started": "2024-06-17T23:37:06.170417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Sentiment'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Sentiment.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma mais elegante..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:09.496446Z",
     "iopub.status.busy": "2024-06-17T23:37:09.496046Z",
     "iopub.status.idle": "2024-06-17T23:37:09.558105Z",
     "shell.execute_reply": "2024-06-17T23:37:09.556801Z",
     "shell.execute_reply.started": "2024-06-17T23:37:09.496415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hole": 0.3,
         "labels": [
          "Negativo",
          "Neutro",
          "Positivo"
         ],
         "marker": {
          "colors": [
           "red",
           "orange",
           "blue"
          ],
          "line": {
           "color": "black",
           "width": 1.5
          }
         },
         "opacity": 0.8,
         "textinfo": "percent+value+label",
         "textposition": "auto",
         "type": "pie",
         "values": [
          860,
          3130,
          1852
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribuição Percentual"
        },
        "xaxis": {
         "title": {
          "text": "Sources"
         }
        },
        "yaxis": {
         "title": {
          "text": "Total"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_counts = df['Sentiment'].value_counts().sort_index()\n",
    "\n",
    "sentiment_labels = ['Negativo', 'Neutro', 'Positivo']\n",
    "sentiment_colors = ['red', 'orange', 'blue']\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=sentiment_labels,#sentiment_counts.index, \n",
    "                             values=sentiment_counts.values,\n",
    "                             textinfo='percent+value+label',\n",
    "                             marker_colors=sentiment_colors,\n",
    "                             textposition='auto',\n",
    "                             hole=.3)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Distribuição Percentual',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(\n",
    "        title='Sources',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Total',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_color='black', \n",
    "                  marker_line_width=1.5, \n",
    "                  opacity=0.8)\n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:14.700077Z",
     "iopub.status.busy": "2024-06-17T23:37:14.699332Z",
     "iopub.status.idle": "2024-06-17T23:37:14.708278Z",
     "shell.execute_reply": "2024-06-17T23:37:14.707033Z",
     "shell.execute_reply.started": "2024-06-17T23:37:14.700038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convertendo as classes em \"categorias\"\n",
    "\n",
    "dicto = {'positive': 1, 'neutral': 0 , 'negative': -1}\n",
    "\n",
    "df.Sentiment = df.Sentiment.map(dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:16.366955Z",
     "iopub.status.busy": "2024-06-17T23:37:16.366514Z",
     "iopub.status.idle": "2024-06-17T23:37:16.386616Z",
     "shell.execute_reply": "2024-06-17T23:37:16.385242Z",
     "shell.execute_reply.started": "2024-06-17T23:37:16.366918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classical_model(df, bow=False, TFIDF=False, Ngram=False,\n",
    "                    model=linear_model.LogisticRegression(solver='liblinear')):\n",
    "    '''\n",
    "    Automatiza modelos de ML clássicos para treinar e avaliar na base de dados\n",
    "\n",
    "    Args:\n",
    "    df : pandas DataFrame\n",
    "        Base de dados em DataFrame\n",
    "    bow : bool\n",
    "        Flag para usar bag of words (binary, count, or frequency)\n",
    "    TFIDF : bool\n",
    "        Flag para usar Tfidf \n",
    "    Ngram : tuple\n",
    "        Shape do intervalo em Ngram ((1,2) para bigrams)\n",
    "    model : scikit-learn estimator\n",
    "        Modelo de ML para treinamento e inferência\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    if bow:\n",
    "        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    elif TFIDF:\n",
    "        count_vec = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    elif Ngram:\n",
    "        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None, ngram_range=Ngram)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.Sentence, df.Sentiment, test_size=0.2,\n",
    "                                                 random_state=42, stratify=df.Sentiment, shuffle=True)\n",
    "    x_train.reset_index(inplace=True, drop=True)\n",
    "    x_test.reset_index(inplace=True, drop=True)\n",
    "    y_train.reset_index(inplace=True, drop=True)\n",
    "    y_test.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Vamos utilizar o método de validação cruzada estratificada para avaliar as métricas de teste\n",
    "    # Importante pois nossa base é altamente desbalanceada\n",
    "    np.random.seed(42)\n",
    "    n_splits = 5\n",
    "    kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    mean_precision = 0\n",
    "    mean_recall = 0\n",
    "    for train, val in kf.split(X=x_train, y=y_train):\n",
    "    \n",
    "        xtrain = x_train[train]\n",
    "        xval = x_train[val]\n",
    "        ytrain = y_train[train]\n",
    "        yval = y_train[val]\n",
    "\n",
    "        count_vec.fit(xtrain)\n",
    "        xtrain = count_vec.transform(xtrain)\n",
    "        xval = count_vec.transform(xval)\n",
    "\n",
    "        model.fit(xtrain, ytrain)\n",
    "        preds = model.predict(xval)\n",
    "        precision = precision_score(yval, preds, average='macro')\n",
    "        recall = recall_score(yval, preds, average='macro')\n",
    "        mean_precision+=precision\n",
    "        mean_recall+=recall\n",
    "        print('precision score:', precision)\n",
    "        print('recall score:', recall)\n",
    "        print(\"========================================================\")\n",
    "    \n",
    "    mean_precision/=n_splits\n",
    "    mean_recall/=n_splits\n",
    "    print(\"Média sobre os\",n_splits,\"folds:\")\n",
    "    print(\"Precisão:\", mean_precision, \"Revocação:\", mean_recall)\n",
    "\n",
    "    if bow:\n",
    "        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    elif TFIDF:\n",
    "        count_vec = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "    elif Ngram:\n",
    "        count_vec = CountVectorizer(tokenizer=word_tokenize, token_pattern=None, ngram_range=Ngram)\n",
    "\n",
    "    count_vec.fit(x_train)\n",
    "    x_train = count_vec.transform(x_train)\n",
    "    x_test = count_vec.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 1:\n",
    "### Regressão Logística + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:19.388403Z",
     "iopub.status.busy": "2024-06-17T23:37:19.387964Z",
     "iopub.status.idle": "2024-06-17T23:37:42.052244Z",
     "shell.execute_reply": "2024-06-17T23:37:42.050944Z",
     "shell.execute_reply.started": "2024-06-17T23:37:19.388367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\joaov/nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\joaov\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Modelo de linha de base.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Vamos começar com um modelo de regressão logística, pois é o mais rápido para dados esparsos de alta dimensão!\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassical_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36mclassical_model\u001b[1;34m(df, bow, TFIDF, Ngram, model)\u001b[0m\n\u001b[0;32m     48\u001b[0m ytrain \u001b[38;5;241m=\u001b[39m y_train[train]\n\u001b[0;32m     49\u001b[0m yval \u001b[38;5;241m=\u001b[39m y_train[val]\n\u001b[1;32m---> 51\u001b[0m \u001b[43mcount_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m xtrain \u001b[38;5;241m=\u001b[39m count_vec\u001b[38;5;241m.\u001b[39mtransform(xtrain)\n\u001b[0;32m     53\u001b[0m xval \u001b[38;5;241m=\u001b[39m count_vec\u001b[38;5;241m.\u001b[39mtransform(xval)\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1323\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m        Fitted vectorizer.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:110\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\joaov\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\joaov/nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\joaov\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\joaov\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Modelo de linha de base.\n",
    "# Vamos começar com um modelo de regressão logística, pois é o mais rápido para dados esparsos de alta dimensão!\n",
    "\n",
    "classical_model(df, bow=True, model=linear_model.LogisticRegression(solver='liblinear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os rótulos **1 e 0 têm pontuação superior a 70 por cento**, mas a pontuação do rótulo **-1 é muito baixa**, portanto, podemos concluir que precisamos continuar modelando até que essas pontuações melhorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 2: \n",
    "\n",
    "### Naive Bayes + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:37:42.055474Z",
     "iopub.status.busy": "2024-06-17T23:37:42.054655Z",
     "iopub.status.idle": "2024-06-17T23:38:01.075614Z",
     "shell.execute_reply": "2024-06-17T23:38:01.074424Z",
     "shell.execute_reply.started": "2024-06-17T23:37:42.055428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classical_model(df, bow=True, model=MultinomialNB()) # multiclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É evidente que para a **classe -1 os valores das métricas melhoraram um pouco**, então este modelo será o novo modelo de linha de base para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 3: \n",
    "\n",
    "### Naive Bayes com TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:38:01.077721Z",
     "iopub.status.busy": "2024-06-17T23:38:01.07735Z",
     "iopub.status.idle": "2024-06-17T23:38:20.120759Z",
     "shell.execute_reply": "2024-06-17T23:38:20.119415Z",
     "shell.execute_reply.started": "2024-06-17T23:38:01.077689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classical_model(df, model=MultinomialNB(), TFIDF=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infelizmente a **pontuação de revocação para o rótulo -1 está insatisfatória**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 4: \n",
    "\n",
    "### Naive Bayes com N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:38:20.123909Z",
     "iopub.status.busy": "2024-06-17T23:38:20.123477Z",
     "iopub.status.idle": "2024-06-17T23:38:42.306584Z",
     "shell.execute_reply": "2024-06-17T23:38:42.305328Z",
     "shell.execute_reply.started": "2024-06-17T23:38:20.12387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classical_model(df, model=MultinomialNB(), Ngram=(1,2))\n",
    "# sugestão, avaliem com outras formações n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem N-gram **não surtiu efeito expressivamente positivo no valor das métricas**. Portanto, é evidente que o modelo de linha de base (NB + BoW) ainda é o melhor até agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remover todas as palavras \"irrelevantes\"** pode alterar o contexto da frase, fique atento(a).\n",
    "\n",
    "Por exemplo, **\"Ele não é uma boa pessoa\"** será alterado para **\" 'Ele' , 'boa', 'pessoa'\"** que é o completo oposto da frase.\n",
    "\n",
    "Vale ressaltar que não é porque estamos removendo palavras \"irrelevantes\" que os resultados dos modelos irão melhorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:40:41.06411Z",
     "iopub.status.busy": "2024-06-17T21:40:41.063645Z",
     "iopub.status.idle": "2024-06-17T21:40:41.070103Z",
     "shell.execute_reply": "2024-06-17T21:40:41.068715Z",
     "shell.execute_reply.started": "2024-06-17T21:40:41.064065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Agora vamos fazer uma limpeza nos dados de texto e aplicá-los ao modelo de linha de base e comparar as precisões.\n",
    "# NÃO FUNCIONOU\n",
    "# Erro na instalação do wordnet, mesmo após várias tentativas\n",
    "\n",
    "# def process_text(text):\n",
    "#     \n",
    "#     text = word_tokenize(text) # tokeniza o texto\n",
    "#     text = [re.sub('[^A-Za-z]+', '', word) for word in text] # esta linha substitui qualquer espaço em branco antes da palavra removendo o espaço\n",
    "#     text = [word.lower() for word in text if word.isalpha()] # minuscula\n",
    "#     text = [word for word in text if word not in stop_words]\n",
    "#     text = [WordNetLemmatizer().lemmatize(word) for word in text] # lematização de palavras, então quando vemos \"pessoas\" e \"pessoa\", ambas são tratadas como uma palavra \"pessoa\"\n",
    "#     text = ' '.join(text) # concatenação\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:38:42.308079Z",
     "iopub.status.busy": "2024-06-17T23:38:42.307736Z",
     "iopub.status.idle": "2024-06-17T23:38:42.316141Z",
     "shell.execute_reply": "2024-06-17T23:38:42.314689Z",
     "shell.execute_reply.started": "2024-06-17T23:38:42.30805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stop_words = [i for i in stopwords.words('english') if \"n't\" not in i and i not in ('not','no')]\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:38:42.317907Z",
     "iopub.status.busy": "2024-06-17T23:38:42.317509Z",
     "iopub.status.idle": "2024-06-17T23:38:42.338549Z",
     "shell.execute_reply": "2024-06-17T23:38:42.3371Z",
     "shell.execute_reply.started": "2024-06-17T23:38:42.317856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text = 'He is not a good person'\n",
    "token_text = word_tokenize(text)\n",
    "[ word for word in token_text if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:40:41.110681Z",
     "iopub.status.busy": "2024-06-17T21:40:41.110281Z",
     "iopub.status.idle": "2024-06-17T21:40:41.118948Z",
     "shell.execute_reply": "2024-06-17T21:40:41.117601Z",
     "shell.execute_reply.started": "2024-06-17T21:40:41.110642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NÃO FUNCIONOU\n",
    "# df.Sentence = df.Sentence.apply(process_text) # esta linha aplica a função process_text à \"Sentença\" no conjunto de dados\n",
    "# df.Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 5:\n",
    "\n",
    "### Texto processado + BoW + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:38:42.3407Z",
     "iopub.status.busy": "2024-06-17T23:38:42.340297Z",
     "iopub.status.idle": "2024-06-17T23:39:01.392142Z",
     "shell.execute_reply": "2024-06-17T23:39:01.390753Z",
     "shell.execute_reply.started": "2024-06-17T23:38:42.340666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classical_model(df, model=MultinomialNB(), bow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após alguma limpeza de texto, esta abordagem supera o modelo base em alguns casos, mas perde em outros, ficando praticamente no mesmo patamar. **Superamos nosso modelo de linha de base por uma pequena margem em revocação**, o que esperávamos. Iremos utilizar o modelo acima como nosso novo modelo de linha de base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos entrar nos modelos com **embedding de palavras**\n",
    "\n",
    "Nos modelos acima, cada token de palavra é convertido em tokens inteiros por (BoW e TF-IDF). Agora vamos converter esses **tokens inteiros em vetores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 6:\n",
    "\n",
    "### Vetor FastText + Naive Bayes Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:39:01.395016Z",
     "iopub.status.busy": "2024-06-17T23:39:01.393987Z",
     "iopub.status.idle": "2024-06-17T23:39:01.402777Z",
     "shell.execute_reply": "2024-06-17T23:39:01.401559Z",
     "shell.execute_reply.started": "2024-06-17T23:39:01.39497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Neste modelo usaremos vetores FastText, e também converteremos cada vetor de palavras em vetores de frases.\n",
    "# O código foi retirado de https://fasttext.cc/docs/en/english-vectors.html, este código divide cada vetor por\n",
    "# espaço e nova linha, para mais informações acesse o link acima.\n",
    "\n",
    "def sentence_to_vec(sentence, embedding_dict, tokenizer):\n",
    "    # Esta função converte uma frase em um vetor de vetores de palavras\n",
    "    words = tokenizer(sentence)\n",
    "    embedding_list = []\n",
    "    for word in words:\n",
    "        if word in embedding_dict:\n",
    "            embedding_list.append(embedding_dict[word])\n",
    "    if len(embedding_list) == 0:\n",
    "        # se nenhum vetor for encontrado, retorna zeros\n",
    "        return np.zeros(300)\n",
    "    embedding_list = np.array(embedding_list)\n",
    "    vector = embedding_list.sum(axis=0) / len(embedding_list)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:39:01.40498Z",
     "iopub.status.busy": "2024-06-17T23:39:01.404418Z",
     "iopub.status.idle": "2024-06-17T23:39:01.423608Z",
     "shell.execute_reply": "2024-06-17T23:39:01.422397Z",
     "shell.execute_reply.started": "2024-06-17T23:39:01.404935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.Sentence, df.Sentiment, test_size=0.2,\n",
    "                                                 random_state=42, stratify=df.Sentiment, shuffle=True)\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "x_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:40:59.068321Z",
     "iopub.status.busy": "2024-06-17T21:40:59.067788Z",
     "iopub.status.idle": "2024-06-17T21:40:59.077385Z",
     "shell.execute_reply": "2024-06-17T21:40:59.075932Z",
     "shell.execute_reply.started": "2024-06-17T21:40:59.068279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NÃO FUNCIONOU\n",
    "# [Errno 2] No such file or directory: './fasttext_embedding/crawl-300d-2M.vec'\n",
    "\n",
    "# Inicia a classe kfold do módulo model_selection\n",
    "# n_splits = 5\n",
    "# kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# mean_precision = 0\n",
    "# mean_recall = 0\n",
    "\n",
    "# Carrega os embeddings na memória\n",
    "# print(\"Loading embeddings\")\n",
    "#if embeddings==None:\n",
    "# embeddings = KeyedVectors.load_word2vec_format('./fasttext_embedding/crawl-300d-2M.vec')\n",
    "\n",
    "# Crie embeddings de frases\n",
    "# print(\"Creating sentence vectors\")\n",
    "# vectors = []\n",
    "# for sentence in x_train.values:\n",
    "#     vectors.append(sentence_to_vec(sentence=sentence, embedding_dict=embeddings, tokenizer=word_tokenize))\n",
    "# vectors = np.array(vectors)\n",
    "\n",
    "# for fold_, (train_, valid_) in enumerate(kf.split(X=x_train, y=y_train)):\n",
    "#     print(\"Fold: \", fold_)\n",
    "#     xtrain = vectors[train_, :]\n",
    "#     ytrain = y_train[train_]\n",
    "#     xtest = vectors[valid_, :]\n",
    "#     ytest = y_train[valid_]\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     x_train_scaled = scaler.fit_transform(xtrain)\n",
    "#     x_test_scaled = scaler.transform(xtest)\n",
    "    \n",
    "#     model = MultinomialNB()\n",
    "#     model.fit(x_train_scaled, ytrain)\n",
    "    \n",
    "#     y_pred = model.predict(x_test_scaled)\n",
    "#     pres_score = precision_score(ytest, y_pred, average='macro')\n",
    "#     rec_score = recall_score(ytest, y_pred, average='macro')\n",
    "#     print('Precision and recall scores:', pres_score, rec_score)\n",
    "#     print(\"======================================================\")\n",
    "\n",
    "#print(classification_report(y_test, y_pred, labels=[1, -1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incrível...É o nosso modelo com pior desempenho até agora!**\n",
    "\n",
    "Continuaremos tentando com outros modelos e métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 7: \n",
    "\n",
    "### BoW + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:39:01.427528Z",
     "iopub.status.busy": "2024-06-17T23:39:01.427148Z",
     "iopub.status.idle": "2024-06-17T23:39:58.068331Z",
     "shell.execute_reply": "2024-06-17T23:39:58.066891Z",
     "shell.execute_reply.started": "2024-06-17T23:39:01.427497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Vamos avaliar a SVM com BoW\n",
    "classical_model(df, model=SVC(C=10), bow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, os resultados estão bem ruins...hipóteses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 8: \n",
    "\n",
    "### BoW + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:39:58.070564Z",
     "iopub.status.busy": "2024-06-17T23:39:58.070114Z",
     "iopub.status.idle": "2024-06-17T23:41:06.547685Z",
     "shell.execute_reply": "2024-06-17T23:41:06.546515Z",
     "shell.execute_reply.started": "2024-06-17T23:39:58.070523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Vamos avaliar a Random Forest com BoW\n",
    "classical_model(df, model=RandomForestClassifier(n_estimators=70, ccp_alpha=0.001, random_state=42), bow=True)\n",
    "# Estes hiper-parâmetros foram ajustados \"na mão\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo RF está se saindo bem, porém ainda está com dificuldade em melhorar a revocação da classe -1..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussão:\n",
    "\n",
    "#### O que você imagina estar influenciando na dificuldade dos modelos em atingir bons resultados, além do desbalanceamento das classes?\n",
    "\n",
    "#### Levante hipóteses a partir da teoria abordada, da sua observação e da experiência..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problemas:\n",
    "- O corpus é muito pequeno pelo que ele se proprõe a rotular: a precisão dificilmente será 100%, data a complexidade e unicidade de algumas das amostras;\n",
    "- Existem muitas amostras da categoria 'neutro', o que torna o modelo tendencioso e agrava o primeiro problema para as categorias 'negativo' e 'positivo';\n",
    "- Várias amostras do corpus possuem links ao final, isso pode estar prejudicando muito o aprendizado e a classificação por parte do modelo;\n",
    "- Quase todas as amostras possuem substantivos , nomes e valores, irrelevantes para o objetivo do modelo;\n",
    "- O nível de formalidade varia muito de uma amostra para outra, seria necessária uma amostra muito maior ou uma aproximação apropriada para lidar com esta variação;\n",
    "- Algumas amostras fazem sentido como uma manchete de uma notícia, outras não possuem sentido por si só e não deveriam ser classificadas, pois podem entrar para o conjunto 'neutro' devido a falta de contexto;\n",
    "\n",
    "#### Possível solução para o aumento da precisão:\n",
    "- Remover amostras muito longas e fora de contexto, sobretudo classificadas como 'neutro';\n",
    "- Remover/tratar amostras com links, valores, nomes e substantivos, pois o modelo deveria lidar somente com a parte relevante das amostras.\n",
    "- Enriquecer o corpus com mais amostras, e em seguida realizar nestas novas amostras as duas etapas acima;\n",
    "- Testar novamente e realizar uma nova análise;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESAFIO:\n",
    "\n",
    "Replicar a atividade desta aula prática traduzindo-a para a língua portuguesa.\n",
    "\n",
    "Você deve utilizar o mesmo banco de dados, os mesmos modelos, e a mesma estrutura de treinamento e avaliação.\n",
    "\n",
    "Sua tarefa será buscar, integrar, e aplicar soluções rápidas para resolver o problema de tradução do banco de dados, visto que atualmente é um problema fácil de ser resolvido. \n",
    "\n",
    "Obs.: Note que não estamos abordando o problema de desempenho dos modelos\n",
    "\n",
    "Documente (em markdown mesmo) as considerações que fizer, as buscas, e decisões para a resolução do problema de análise de sentimento traduzido.\n",
    "\n",
    "Esta é uma aplicação didática, para fins de desenvolvimento técnico de soluções práticas do dia a dia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolução do desafio:\n",
    "\n",
    "#### ChatGPT + googletrans\n",
    "- Realizei algumas consultas no ChatGPT para verificar como uma planilha .csv pode ser traduzida para o português. Ele me sugeriu o uso da biblioteca google-trans.\n",
    "- Tive vários problemas com o uso desta biblioteca, pois ficava muito tempo rodando (de uma hora a uma hora e meia) e no final retornava erros dizendo que o formato que estava tentando traduzir era um NoneType, não uma string;\n",
    "- Depois de várias execuções perdidas, resolvi colocar um try..except para pular as traduções com erro, que acreditava ser uma minoria, depois de ver o resultado, descobri que a biblioteca simplismente parava de traduzir a partir de um ponto aleatório do dataset;\n",
    "- Inicialmente, acreditava que este ponto aleatório era sempre uma linha irregular que quebrava o tradutor, o que não se sustentou após a remoção de algumas destas linhas da planilha;\n",
    "- Após verificar isso, parti para a tradução fracionada dos resultados de 1000 em 1000, tendo sucesso apenas na tradução das 2000 primeiras linhas;\n",
    "- Acredito que a causa do problema esteja relacionada a políticas do próprio Google Tradutor;\n",
    "\n",
    "#### ChatGPT, DeepL Translate\n",
    "- Pedi para que o ChatGPT e o DeepL Translate traduzissem este dataset, mas o primeiro não conseguiu importar a biblioteca googletrans dentro do seu código, e o segundo não permite a tradução de um texto maior do que 1500 acaracteres;\n",
    "\n",
    "#### ChatGPT + googletrans\n",
    "- Após novas consultas, o ChatGPT me mostrou uma abordagem com o uso da biblioteca deep_translator. Infelizmente, ela ficou um bom tempo rodando e tudo indicava que o resultado seria similiar ao do googletrans;\n",
    "- Resolvi adotar a mesma técnica de fracionamento, tendo sucesso ao traduzir as mais de 3000 frases restantes em planihlas separadas;\n",
    "- Finalmente, as planilhas foram unificadas e salvas em um dataset online, sem erros de junção ou tradução verificados;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:43:21.771199Z",
     "iopub.status.busy": "2024-06-17T21:43:21.770772Z",
     "iopub.status.idle": "2024-06-17T21:43:44.325469Z",
     "shell.execute_reply": "2024-06-17T21:43:44.323976Z",
     "shell.execute_reply.started": "2024-06-17T21:43:21.771165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:57:10.655025Z",
     "iopub.status.busy": "2024-06-17T21:57:10.653773Z",
     "iopub.status.idle": "2024-06-17T22:03:47.766218Z",
     "shell.execute_reply": "2024-06-17T22:03:47.765016Z",
     "shell.execute_reply.started": "2024-06-17T21:57:10.654984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "\n",
    "def texto_para_portugues_google_trans(text):\n",
    "    translator = Translator()\n",
    "    \n",
    "    try:\n",
    "        translation = translator.translate(text, src='en', dest='pt')\n",
    "        return translation.text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/sentiment-analysis/sentiment_analysis.csv')\n",
    "# df = df.head(1000)\n",
    "# df = df.iloc[1000:2000]\n",
    "df = df.iloc[2000:3000]\n",
    "\n",
    "df['Sentence'] = df['Sentence'].apply(texto_para_portugues_google_trans)\n",
    "\n",
    "# Salvar o DataFrame traduzido em um novo arquivo CSV\n",
    "# df.to_csv('/kaggle/working/sentiment_analysis_pt_br_parte_1.csv', index=False)\n",
    "# df.to_csv('/kaggle/working/sentiment_analysis_pt_br_parte_2.csv', index=False)\n",
    "df.to_csv('/kaggle/working/sentiment_analysis_pt_br_parte_3.csv', index=False)\n",
    "\n",
    "print('CSV traduzido salvo com sucesso.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T22:06:09.140734Z",
     "iopub.status.busy": "2024-06-17T22:06:09.14029Z",
     "iopub.status.idle": "2024-06-17T22:06:24.757897Z",
     "shell.execute_reply": "2024-06-17T22:06:24.756178Z",
     "shell.execute_reply.started": "2024-06-17T22:06:09.140701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T22:56:42.18123Z",
     "iopub.status.busy": "2024-06-17T22:56:42.18076Z",
     "iopub.status.idle": "2024-06-17T23:01:29.341075Z",
     "shell.execute_reply": "2024-06-17T23:01:29.339901Z",
     "shell.execute_reply.started": "2024-06-17T22:56:42.181197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def texto_para_portugues_deep(text):\n",
    "    translator = GoogleTranslator(source='en', target='pt')\n",
    "    return translator.translate(text)\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/sentiment-analysis/sentiment_analysis.csv')\n",
    "df = df.iloc[5000:5842]\n",
    "df['Sentence'] = df['Sentence'].apply(texto_para_portugues_deep)\n",
    "\n",
    "# Salvar o DataFrame traduzido em um novo arquivo CSV\n",
    "df.to_csv('/kaggle/working/sentiment_analysis_pt_br_deep_tr_5000_5842.csv', index=False)\n",
    "\n",
    "print('CSV traduzido salvo com sucesso.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T23:16:56.189548Z",
     "iopub.status.busy": "2024-06-17T23:16:56.189118Z",
     "iopub.status.idle": "2024-06-17T23:16:56.277708Z",
     "shell.execute_reply": "2024-06-17T23:16:56.276282Z",
     "shell.execute_reply.started": "2024-06-17T23:16:56.189516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "paths = [\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_parte_1.csv',\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_parte_2.csv',\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_deep_tr_2000_3000.csv',\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_deep_tr_3000_4000.csv',\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_deep_tr_4000_5000.csv',\n",
    "    '/kaggle/working/sentiment_analysis_pt_br_deep_tr_5000_5842.csv'\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "cmb_df = pd.concat(dfs, ignore_index=True)\n",
    "cmb_df.to_csv('/kaggle/working/sentiment_analysis_pt_br.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referências\n",
    "- https://www.hashtagtreinamentos.com/tradutor-de-texto-em-python;\n",
    "- https://github.com/ssut/py-googletrans;\n",
    "- https://pypi.org/project/deep-translator/;"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5223233,
     "sourceId": 8707627,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5229162,
     "sourceId": 8715780,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
